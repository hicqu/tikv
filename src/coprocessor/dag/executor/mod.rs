// Copyright 2017 PingCAP, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// See the License for the specific language governing permissions and
// limitations under the License.

use std::cell::UnsafeCell;
use std::sync::Arc;

use kvproto::coprocessor::KeyRange;
use tipb::executor::{self, ExecType};
use tipb::expression::{Expr, ExprType};
use tipb::schema::ColumnInfo;

use storage::{Snapshot, SnapshotStore};
use util::codec::number;
use util::collections::{HashMap, HashMapEntry as Entry, HashSet};

use coprocessor::codec::datum::{self, Datum, DatumEncoder};
use coprocessor::codec::table::{self, RowColsDict};
use coprocessor::codec::{mysql, Error as CodecError};
use coprocessor::dag::expr::{EvalConfig, EvalContext, EvalWarnings};
use coprocessor::util;
use coprocessor::*;

mod aggregate;
mod aggregation;
mod index_scan;
mod limit;
mod scanner;
mod selection;
mod table_scan;
mod topn;
mod topn_heap;

mod metrics;

pub use self::aggregation::{HashAggExecutor, StreamAggExecutor};
pub use self::index_scan::IndexScanExecutor;
pub use self::limit::LimitExecutor;
pub use self::metrics::*;
pub use self::scanner::{ScanOn, Scanner};
pub use self::selection::SelectionExecutor;
pub use self::table_scan::TableScanExecutor;
pub use self::topn::TopNExecutor;

pub struct ExprColumnRefVisitor {
    cols_offset: HashSet<usize>,
    cols_len: usize,
}

impl ExprColumnRefVisitor {
    pub fn new(cols_len: usize) -> ExprColumnRefVisitor {
        ExprColumnRefVisitor {
            cols_offset: HashSet::default(),
            cols_len,
        }
    }

    pub fn visit(&mut self, expr: &Expr) -> Result<()> {
        if expr.get_tp() == ExprType::ColumnRef {
            let offset = box_try!(number::decode_i64(&mut expr.get_val())) as usize;
            if offset >= self.cols_len {
                return Err(Error::Other(box_err!(
                    "offset {} overflow, should be less than {}",
                    offset,
                    self.cols_len
                )));
            }
            self.cols_offset.insert(offset);
        } else {
            for sub_expr in expr.get_children() {
                self.visit(sub_expr)?;
            }
        }
        Ok(())
    }

    pub fn batch_visit(&mut self, exprs: &[Expr]) -> Result<()> {
        for expr in exprs {
            self.visit(expr)?;
        }
        Ok(())
    }
}

#[derive(Debug)]
pub struct OriginCols {
    pub handle: i64,
    pub data: RowColsDict,
    cols: Arc<Vec<ColumnInfo>>,
}

/// Row generated by aggregation.
#[derive(Debug)]
pub struct AggCols {
    // row's suffix, may be the binary of the group by key.
    suffix: Vec<u8>,
    value: Vec<Datum>,
}

impl AggCols {
    pub fn get_binary(&self) -> Result<Vec<u8>> {
        let mut value =
            Vec::with_capacity(self.suffix.len() + datum::approximate_size(&self.value, false));
        box_try!(value.encode(&self.value, false));
        if !self.suffix.is_empty() {
            value.extend_from_slice(&self.suffix);
        }
        Ok(value)
    }
}

#[derive(Debug)]
pub enum Row {
    Origin(OriginCols),
    Agg(AggCols),
}

impl Row {
    pub fn origin(handle: i64, data: RowColsDict, cols: Arc<Vec<ColumnInfo>>) -> Row {
        Row::Origin(OriginCols::new(handle, data, cols))
    }

    pub fn agg(value: Vec<Datum>, suffix: Vec<u8>) -> Row {
        Row::Agg(AggCols { suffix, value })
    }

    pub fn take_origin(self) -> OriginCols {
        match self {
            Row::Origin(row) => row,
            _ => unreachable!(),
        }
    }

    pub fn get_binary(&self, output_offsets: &[u32]) -> Result<Vec<u8>> {
        match self {
            Row::Origin(row) => row.get_binary(output_offsets),
            Row::Agg(row) => row.get_binary(), // ignore output offsets for aggregation.
        }
    }

    #[cfg(test)]
    pub fn from_datum_vec(data: Vec<Datum>) -> Self {
        Row::Agg(AggCols {
            suffix: vec![],
            value: data,
        })
    }
}

impl OriginCols {
    pub fn new(handle: i64, data: RowColsDict, cols: Arc<Vec<ColumnInfo>>) -> OriginCols {
        OriginCols { handle, data, cols }
    }

    // get binary of each column in order of columns
    pub fn get_binary_cols(&self) -> Result<Vec<Vec<u8>>> {
        let mut res = Vec::with_capacity(self.cols.len());
        for col in self.cols.iter() {
            if col.get_pk_handle() {
                let v = util::get_pk(col, self.handle);
                let bt = box_try!(datum::encode_value(&[v]));
                res.push(bt);
                continue;
            }
            let col_id = col.get_column_id();
            let value = match self.data.get(col_id) {
                None if col.has_default_val() => col.get_default_val().to_vec(),
                None if mysql::has_not_null_flag(col.get_flag() as u64) => {
                    return Err(box_err!("column {} of {} is missing", col_id, self.handle));
                }
                None => box_try!(datum::encode_value(&[Datum::Null])),
                Some(bs) => bs.to_vec(),
            };
            res.push(value);
        }
        Ok(res)
    }

    pub fn get_binary(&self, output_offsets: &[u32]) -> Result<Vec<u8>> {
        // TODO capacity is not enough
        let mut values = Vec::with_capacity(self.data.value.len());
        for offset in output_offsets {
            let col = &self.cols[*offset as usize];
            let col_id = col.get_column_id();
            match self.data.get(col_id) {
                Some(value) => values.extend_from_slice(value),
                None if col.get_pk_handle() => {
                    let pk = util::get_pk(col, self.handle);
                    box_try!(values.encode(&[pk], false));
                }
                None if col.has_default_val() => {
                    values.extend_from_slice(col.get_default_val());
                }
                None if mysql::has_not_null_flag(col.get_flag() as u64) => {
                    return Err(box_err!("column {} of {} is missing", col_id, self.handle));
                }
                None => {
                    box_try!(values.encode(&[Datum::Null], false));
                }
            }
        }
        Ok(values)
    }
}

pub struct RowWithEvalContext<'a, 'b> {
    row: &'a Row,
    ctx: UnsafeCell<&'b mut EvalContext>,
    decoded: UnsafeCell<HashMap<usize, Datum>>,
}

impl<'a, 'b> RowWithEvalContext<'a, 'b> {
    pub fn new(row: &'a Row, ctx: &'b mut EvalContext) -> Self {
        let ctx = UnsafeCell::new(ctx);
        let decoded = UnsafeCell::new(map![]);
        RowWithEvalContext { row, ctx, decoded }
    }

    #[allow(dead_code)]
    pub fn new_with_buffer(
        row: &'a Row,
        ctx: &'b mut EvalContext,
        mut buffer: HashMap<usize, Datum>,
    ) -> Self {
        buffer.clear();
        let ctx = UnsafeCell::new(ctx);
        let decoded = UnsafeCell::new(buffer);
        RowWithEvalContext { row, ctx, decoded }
    }

    pub fn ctx(&self) -> &'b mut EvalContext {
        unsafe { *self.ctx.get() }
    }

    pub fn datum_at(&self, offset: usize) -> ::std::result::Result<&Datum, CodecError> {
        match *self.row {
            Row::Agg(ref agg_cols) => Ok(&agg_cols.value[offset]),
            Row::Origin(ref origin_cols) => match self.decoded().entry(offset) {
                Entry::Occupied(e) => Ok(e.into_mut()),
                Entry::Vacant(e) => {
                    let col = &origin_cols.cols[offset];
                    let datum = if col.get_pk_handle() {
                        util::get_pk(col, origin_cols.handle)
                    } else {
                        match origin_cols.data.get(col.get_column_id()) {
                            None if col.has_default_val() => {
                                let mut def = col.get_default_val();
                                table::decode_col_value(&mut def, self.ctx(), col)?
                            }
                            None if mysql::has_not_null_flag(col.get_flag() as u64) => {
                                return Err(CodecError::InvalidNullColumn);
                            }
                            None => Datum::Null,
                            Some(mut bs) => table::decode_col_value(&mut bs, self.ctx(), col)?,
                        }
                    };
                    Ok(e.insert(datum))
                }
            },
        }
    }

    fn decoded(&self) -> &mut HashMap<usize, Datum> {
        unsafe { &mut *self.decoded.get() }
    }
}

pub trait Executor {
    fn next(&mut self) -> Result<Option<Row>>;
    fn collect_output_counts(&mut self, counts: &mut Vec<i64>);
    fn collect_metrics_into(&mut self, metrics: &mut ExecutorMetrics);
    fn get_len_of_columns(&self) -> usize;

    /// Only executors with eval computation need to implement `take_eval_warnings`
    /// It returns warnings happened during eval computation.
    fn take_eval_warnings(&mut self) -> Option<EvalWarnings> {
        None
    }

    /// Only `TableScan` and `IndexScan` need to implement `start_scan`.
    fn start_scan(&mut self) {}

    /// Only `TableScan` and `IndexScan` need to implement `stop_scan`.
    ///
    /// It returns a `KeyRange` the executor has scaned.
    fn stop_scan(&mut self) -> Option<KeyRange> {
        None
    }
}

pub fn build_exec<S: Snapshot + 'static>(
    execs: Vec<executor::Executor>,
    store: SnapshotStore<S>,
    ranges: Vec<KeyRange>,
    ctx: Arc<EvalConfig>,
    collect: bool,
) -> Result<Box<Executor + Send>> {
    let mut execs = execs.into_iter();
    let first = execs
        .next()
        .ok_or_else(|| Error::Other(box_err!("has no executor")))?;
    let mut src = build_first_executor(first, store, ranges, collect)?;
    for mut exec in execs {
        let curr: Box<Executor + Send> = match exec.get_tp() {
            ExecType::TypeTableScan | ExecType::TypeIndexScan => {
                return Err(box_err!("got too much *scan exec, should be only one"))
            }
            ExecType::TypeSelection => Box::new(SelectionExecutor::new(
                exec.take_selection(),
                Arc::clone(&ctx),
                src,
            )?),
            ExecType::TypeAggregation => Box::new(HashAggExecutor::new(
                exec.take_aggregation(),
                Arc::clone(&ctx),
                src,
            )?),
            ExecType::TypeStreamAgg => Box::new(StreamAggExecutor::new(
                Arc::clone(&ctx),
                src,
                exec.take_aggregation(),
            )?),
            ExecType::TypeTopN => {
                Box::new(TopNExecutor::new(exec.take_topN(), Arc::clone(&ctx), src)?)
            }
            ExecType::TypeLimit => Box::new(LimitExecutor::new(exec.take_limit(), src)),
        };
        src = curr;
    }
    Ok(src)
}

// We have trait objects which requires 'static.
fn build_first_executor<S: Snapshot + 'static>(
    mut first: executor::Executor,
    store: SnapshotStore<S>,
    ranges: Vec<KeyRange>,
    collect: bool,
) -> Result<Box<Executor + Send>> {
    match first.get_tp() {
        ExecType::TypeTableScan => {
            let ex = Box::new(TableScanExecutor::new(
                first.take_tbl_scan(),
                ranges,
                store,
                collect,
            )?);
            Ok(ex)
        }
        ExecType::TypeIndexScan => {
            let unique = first.get_idx_scan().get_unique();
            let ex = Box::new(IndexScanExecutor::new(
                first.take_idx_scan(),
                ranges,
                store,
                unique,
                collect,
            )?);
            Ok(ex)
        }
        _ => Err(box_err!(
            "first exec type should be *Scan, but get {:?}",
            first.get_tp()
        )),
    }
}
